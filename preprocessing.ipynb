{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc061ade",
   "metadata": {},
   "source": [
    "# **00 Import & Install Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f526fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059ec92",
   "metadata": {},
   "source": [
    "# **01 Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1206e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job dataset\n",
    "url_job = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/jobstreet_data.csv\"\n",
    "df_job = pd.read_csv(url_job)\n",
    "\n",
    "# job dataset\n",
    "url_course = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/jobstreet_data.csv\"\n",
    "df_course = pd.read_csv(url_course)\n",
    "\n",
    "# Load slang dictionary\n",
    "url_slang = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/slang.csv\"\n",
    "df_slang = pd.read_csv(url_slang)\n",
    "slang_dict = dict(zip(df_slang['slang'], df_slang['formal']))\n",
    "additional_slang = {}  \n",
    "slang_dict.update(additional_slang)\n",
    "\n",
    "# Load stopword \n",
    "url_stopwords = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/stopword.csv\"\n",
    "stopword_manual = pd.read_csv(url_stopwords, header=None)\n",
    "custom_stopwords = set(stopword_manual.iloc[:, 0].str.lower())\n",
    "custom_stopwords.update([]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6fada",
   "metadata": {},
   "source": [
    "# **02 Overview & Preprocessing** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44bf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d552ffc",
   "metadata": {},
   "source": [
    "# **03 Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454976da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. lowercase\n",
    "def lowercase_columns(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.lower()\n",
    "    return df\n",
    "\n",
    "# 2. clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[\\n\\r\\t]+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"[,.!?]\", \"\", text)\n",
    "    return np.nan if text == \"\" else text\n",
    "\n",
    "# 3. translate to english\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    except:\n",
    "        return text \n",
    "\n",
    "# 4. replace slang\n",
    "def replace_slang(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    words = text.split()\n",
    "    return \" \".join([slang_dict.get(w, w) for w in words])\n",
    "\n",
    "# 5. tokenize\n",
    "def tokenizing_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# 6. remove stopword\n",
    "factory_stopword = StopWordRemoverFactory()\n",
    "stopwords_nltk = set(stopwords.words('english'))\n",
    "\n",
    "def remove_manual_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in custom_stopwords]\n",
    "\n",
    "# 7. lemmatization\n",
    "def lemmatize_flex(word):\n",
    "    lemma_v = Word(word).lemmatize(\"v\")\n",
    "    return lemma_v if lemma_v != word else Word(word).lemmatize(\"n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907dede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d41102a8",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6269a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b134d0d",
   "metadata": {},
   "source": [
    "## Saving Cleaned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccc0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
